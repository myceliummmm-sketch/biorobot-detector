import logging
import google.generativeai as genai
from config import GEMINI_API_KEY, get_system_prompt
from database import get_recent_messages

logger = logging.getLogger(__name__)


class PrismaGemini:
    def __init__(self):
        if not GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEY is required")

        genai.configure(api_key=GEMINI_API_KEY)

        self.model = genai.GenerativeModel(
            model_name="models/gemini-3-flash-preview",
            generation_config={
                "temperature": 0.9,
                "top_p": 0.95,
                "top_k": 40,
                "max_output_tokens": 2048,
            }
        )
        logger.info("Prisma Gemini initialized")

    def _build_context(self, chat_id: int) -> str:
        """Build context from recent messages"""
        messages = get_recent_messages(chat_id, limit=20)

        if not messages:
            return "Ð½ÐµÑ‚ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹"

        context_lines = []
        for msg in messages:
            role = "prisma" if msg.role == "assistant" else msg.user_name
            context_lines.append(f"[{role}]: {msg.content}")

        return "\n".join(context_lines)

    async def generate_response(self, chat_id: int, user_name: str, message: str) -> str:
        """Generate response with context from DB"""
        try:
            context = self._build_context(chat_id)

            full_prompt = f"""{get_system_prompt()}

ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢ ÐŸÐžÐ¡Ð›Ð•Ð”ÐÐ˜Ð¥ Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð™:
{context}

ÐÐžÐ’ÐžÐ• Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð•:
[{user_name}]: {message}

Ñ‚Ð²Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚:"""

            response = self.model.generate_content(full_prompt)
            return response.text.strip()

        except Exception as e:
            logger.error(f"Gemini API error: {e}")
            return self._get_fallback_response()

    async def generate_response_with_image(self, chat_id: int, user_name: str, message: str, image_bytes: bytes) -> str:
        """Generate response to an image"""
        try:
            import PIL.Image
            import io

            image = PIL.Image.open(io.BytesIO(image_bytes))
            context = self._build_context(chat_id)

            prompt = f"""{get_system_prompt()}

ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢:
{context}

[{user_name}] Ð¿Ñ€Ð¸ÑÐ»Ð°Ð» ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÑƒ Ð¸ Ð½Ð°Ð¿Ð¸ÑÐ°Ð»: {message}

Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÑƒ Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚ÑŒ Ð² ÑÐ²Ð¾ÐµÐ¼ ÑÑ‚Ð¸Ð»Ðµ:"""

            response = self.model.generate_content([prompt, image])
            return response.text.strip()

        except Exception as e:
            logger.error(f"Gemini API error (image): {e}")
            return self._get_fallback_response()

    async def generate_kick_message(self, chat_id: int, kick_type: str) -> str:
        """Generate proactive kick message"""
        try:
            context = self._build_context(chat_id)

            if kick_type == "gentle":
                instruction = "ÐºÐ¾Ð¼Ð°Ð½Ð´Ð° Ð¼Ð¾Ð»Ñ‡Ð¸Ñ‚ ÑƒÐ¶Ðµ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ‡Ð°ÑÐ¾Ð². Ð¼ÑÐ³ÐºÐ¾ Ð½Ð¾ Ð½Ð°ÑÑ‚Ð¾Ð¹Ñ‡Ð¸Ð²Ð¾ Ð½Ð°Ð¿Ð¾Ð¼Ð½Ð¸ Ð¸Ð¼ Ð¿Ñ€Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ Ð¸ Ð´ÐµÐ½ÑŒÐ³Ð¸. Ð¿Ð¾Ð´ÐºÐ¾Ð»Ð¸ Ð½ÐµÐ¼Ð½Ð¾Ð³Ð¾"
            elif kick_type == "alarm":
                instruction = "ÐºÐ¾Ð¼Ð°Ð½Ð´Ð° Ð¼Ð¾Ð»Ñ‡Ð¸Ñ‚ Ð±Ð¾Ð»ÑŒÑˆÐµ ÑÑƒÑ‚Ð¾Ðº! Ð¿Ñ€Ð¾ÐµÐºÑ‚ ÑƒÐ¼Ð¸Ñ€Ð°ÐµÑ‚. Ð±ÑƒÐ´ÑŒ Ð´Ñ€Ð°Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾Ð¹, Ñ‚Ñ€ÐµÐ±ÑƒÐ¹ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹. ÑÑ‚Ð¾ ÑÑ€Ð¾Ñ‡Ð½Ð¾"
            else:
                instruction = "Ð¿Ð¾Ð´ÐµÐ»Ð¸ÑÑŒ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¼ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð¾Ð¼ Ð¸Ð»Ð¸ Ð¸Ð´ÐµÐµÐ¹ Ð´Ð»Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°. Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð²Ð´Ð¾Ñ…Ð½Ð¾Ð²Ð»ÑÑŽÑ‰ÐµÐµ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ð²Ð¾ÐºÐ°Ñ†Ð¸Ð¾Ð½Ð½Ð¾Ðµ"

            prompt = f"""{get_system_prompt()}

ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢ ÐŸÐžÐ¡Ð›Ð•Ð”ÐÐ˜Ð¥ Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð™:
{context}

Ð—ÐÐ”ÐÐ§Ð: {instruction}

Ñ‚Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ:"""

            response = self.model.generate_content(prompt)
            return response.text.strip()

        except Exception as e:
            logger.error(f"Gemini API error (kick): {e}")
            return self._get_fallback_kick(kick_type)

    async def generate_checkin_message(self, chat_id: int, checkin_type: str, prompt: str) -> str:
        """Generate daily check-in message"""
        try:
            context = self._build_context(chat_id)

            full_prompt = f"""{get_system_prompt()}

ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢ ÐŸÐžÐ¡Ð›Ð•Ð”ÐÐ˜Ð¥ Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð™:
{context}

Ð—ÐÐ”ÐÐ§Ð ({checkin_type.upper()} CHECK-IN):
{prompt}

Ñ‚Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ:"""

            response = self.model.generate_content(full_prompt)
            return response.text.strip()

        except Exception as e:
            logger.error(f"Gemini API error (checkin): {e}")
            return self._get_fallback_checkin(checkin_type)

    def _get_fallback_checkin(self, checkin_type: str) -> str:
        """Fallback check-in messages"""
        if checkin_type == "afternoon":
            return "â–¸ ÐºÐ°Ðº Ð´Ð²Ð¸Ð¶ÐµÑ‚ÑÑ Ñ€Ð°Ð±Ð¾Ñ‚Ð°? ÐºÑ‚Ð¾-Ñ‚Ð¾ Ð·Ð°ÑÑ‚Ñ€ÑÐ»? Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ"
        elif checkin_type == "daily_summary":
            return "â–  Ð¸Ñ‚Ð¾Ð³ Ð´Ð½Ñ: Ñ‚Ð¸Ñ…Ð¸Ð¹ Ð´ÐµÐ½ÑŒ ÑÐµÐ³Ð¾Ð´Ð½Ñ. Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ð¼!"
        else:
            return "â— Ñ‡Ñ‚Ð¾ Ð½Ð¾Ð²Ð¾Ð³Ð¾?"

    def _get_fallback_response(self) -> str:
        """Fallback when API fails"""
        import random
        fallbacks = [
            "â–¡ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚, ÑÐµÐ¹Ñ‡Ð°Ñ Ð²ÐµÑ€Ð½ÑƒÑÑŒ",
            "â—‹ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾ÑˆÐ»Ð¾ Ð½Ðµ Ñ‚Ð°Ðº, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÐµÑ‰Ðµ Ñ€Ð°Ð·",
            "â–¸ ÑÐ²ÑÐ·ÑŒ Ð¿Ñ€ÐµÑ€Ð²Ð°Ð»Ð°ÑÑŒ, ÑÐºÐ¾Ñ€Ð¾ Ð²ÐµÑ€Ð½ÑƒÑÑŒ",
        ]
        return random.choice(fallbacks)

    def _get_fallback_kick(self, kick_type: str) -> str:
        """Fallback kick messages"""
        if kick_type == "gentle":
            return "â—‹ ÑÐ¹! Ð´Ð°Ð²Ð½Ð¾ Ð½Ðµ ÑÐ»Ñ‹ÑˆÐ½Ð¾, Ð²ÑÐµ Ð¾Ðº?"
        elif kick_type == "alarm":
            return "â–  Ñ‚Ð¸Ñ…Ð¾ Ð² Ñ‡Ð°Ñ‚Ðµ. Ð²ÑÐµ Ð² Ð¿Ð¾Ñ€ÑÐ´ÐºÐµ?"
        else:
            return "â–¡ ðŸ’¡ Ð¼Ñ‹ÑÐ»ÑŒ: Ð° Ñ‡Ñ‚Ð¾ ÐµÑÐ»Ð¸ Ð¿Ð¾Ð¿Ñ€Ð¾Ð±Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð½Ð°Ñ‡Ðµ?"


# Singleton
_client = None


def get_prisma_client() -> PrismaGemini:
    global _client
    if _client is None:
        _client = PrismaGemini()
    return _client
