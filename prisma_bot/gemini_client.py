import logging
import json
import re
import google.generativeai as genai
from config import GEMINI_API_KEY, get_system_prompt
from database import get_recent_messages, get_memory_context, add_memory
from supabase_client import build_project_context, get_project_by_chat_id, save_ai_message

logger = logging.getLogger(__name__)

# YouTube-related keywords
YOUTUBE_KEYWORDS = [
    "youtube", "—é—Ç—É–±", "—é—Ç—é–±", "–∫–∞–Ω–∞–ª", "–≤–∏–¥–µ–æ", "–ø—Ä–æ—Å–º–æ—Ç—Ä", "–ø–æ–¥–ø–∏—Å—á–∏–∫",
    "—Ä–æ–ª–∏–∫", "views", "subscribers", "–∞–Ω–∞–ª–∏—Ç–∏–∫–∞", "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–∞–Ω–∞–ª–∞"
]

# GitHub-related keywords
GITHUB_KEYWORDS = [
    "github", "–≥–∏—Ç—Ö–∞–±", "–≥–∏—Ç", "git", "–∫–æ–º–º–∏—Ç", "commit", "–ø—É–ª–ª —Ä–µ–∫–≤–µ—Å—Ç",
    "pull request", "pr", "–º–µ—Ä–∂", "merge", "—Ä–µ–ø–æ", "—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–∫–æ–¥",
    "issue", "–∏—à—å—é", "–±—Ä–∞–Ω—á", "branch", "–≤–µ—Ç–∫–∞", "–¥–µ–ø–ª–æ–π", "deploy"
]


class PrismaGemini:
    def __init__(self):
        if not GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEY is required")

        genai.configure(api_key=GEMINI_API_KEY)

        self.model = genai.GenerativeModel(
            model_name="models/gemini-3-flash-preview",
            generation_config={
                "temperature": 0.9,
                "top_p": 0.95,
                "top_k": 40,
                "max_output_tokens": 2048,
            }
        )
        logger.info("Prisma Gemini initialized")

    def _build_context(self, chat_id: int) -> str:
        """Build context from recent messages, permanent memory, and project data"""
        # Get project context from Supabase (cards, project info)
        project_context = build_project_context(chat_id)

        # Get permanent memory
        memory_context = get_memory_context(chat_id, limit=15)

        # Get recent messages
        messages = get_recent_messages(chat_id, limit=50)

        if not messages:
            message_context = "–Ω–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"
        else:
            context_lines = []
            for msg in messages:
                role = "prisma" if msg.role == "assistant" else msg.user_name
                context_lines.append(f"[{role}]: {msg.content}")
            message_context = "\n".join(context_lines)

        # Combine all context: project + memory + messages
        parts = []
        if project_context:
            parts.append(project_context)
        if memory_context:
            parts.append(memory_context)
        parts.append(f"=== –ü–û–°–õ–ï–î–ù–ò–ï –°–û–û–ë–©–ï–ù–ò–Ø ===\n{message_context}")

        return "\n\n".join(parts)

    def _check_youtube_context(self, message: str) -> str:
        """Check if message is about YouTube and return stats context if needed"""
        message_lower = message.lower()
        if any(kw in message_lower for kw in YOUTUBE_KEYWORDS):
            try:
                from youtube_client import get_youtube_client
                yt = get_youtube_client()
                if yt.is_available():
                    stats = yt.get_channel_stats()
                    analytics = yt.get_analytics_last_days(7)
                    videos = yt.get_recent_videos(3)

                    lines = ["\n=== –î–ê–ù–ù–´–ï YOUTUBE (–∏—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –æ—Ç–≤–µ—Ç–∞) ==="]
                    if stats:
                        lines.append(f"–ö–∞–Ω–∞–ª: {stats['title']}")
                        lines.append(f"–ü–æ–¥–ø–∏—Å—á–∏–∫–æ–≤: {stats['subscribers']:,}")
                        lines.append(f"–í—Å–µ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {stats['total_views']:,}")
                    if analytics:
                        lines.append(f"–ó–∞ 7 –¥–Ω–µ–π: {analytics['views']:,} –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤, {analytics['subs_net']:+d} –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤")
                    if videos:
                        lines.append("–ü–æ—Å–ª–µ–¥–Ω–∏–µ –≤–∏–¥–µ–æ:")
                        for v in videos:
                            lines.append(f"  - {v['title']}: {v['views']:,} –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤")
                    return "\n".join(lines)
            except Exception as e:
                logger.debug(f"YouTube context error: {e}")
        return ""

    def _check_github_context(self, message: str) -> str:
        """Check if message is about GitHub and return repo context if needed"""
        message_lower = message.lower()
        if any(kw in message_lower for kw in GITHUB_KEYWORDS):
            try:
                from github_client import get_github_client
                gh = get_github_client()
                if gh.is_available():
                    summary = gh.get_full_summary()
                    return f"\n\n=== –î–ê–ù–ù–´–ï GITHUB (–∏—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –æ—Ç–≤–µ—Ç–∞) ===\n{summary}"
            except Exception as e:
                logger.debug(f"GitHub context error: {e}")
        return ""

    async def generate_response(self, chat_id: int, user_name: str, message: str, user_id: int = None) -> str:
        """Generate response with context from DB"""
        try:
            context = self._build_context(chat_id)

            # Add smart context if message is about specific topics
            youtube_context = self._check_youtube_context(message)
            github_context = self._check_github_context(message)

            full_prompt = f"""{get_system_prompt()}

–ö–û–ù–¢–ï–ö–°–¢ –ü–û–°–õ–ï–î–ù–ò–• –°–û–û–ë–©–ï–ù–ò–ô:
{context}{youtube_context}{github_context}

–ù–û–í–û–ï –°–û–û–ë–©–ï–ù–ò–ï:
[{user_name}]: {message}

—Ç–≤–æ–π –æ—Ç–≤–µ—Ç:"""

            response = self.model.generate_content(full_prompt)
            response_text = response.text.strip()

            # Save to Supabase if project exists
            project = get_project_by_chat_id(chat_id)
            if project and user_id:
                save_ai_message(project["id"], user_id, "prisma", "user", message)
                save_ai_message(project["id"], user_id, "prisma", "assistant", response_text)

            # Try to auto-save important info (fire and forget)
            try:
                await self._analyze_and_save_memory(chat_id, user_name, message)
            except Exception as e:
                logger.debug(f"Memory save skipped: {e}")

            return response_text

        except Exception as e:
            logger.error(f"Gemini API error: {e}")
            return self._get_fallback_response()

    async def _analyze_and_save_memory(self, chat_id: int, user_name: str, message: str):
        """Analyze message and save important info to permanent memory"""
        # Skip short messages
        if len(message) < 20:
            return

        analysis_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {user_name}:
"{message}"

–û–ø—Ä–µ–¥–µ–ª–∏, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ–Ω–æ –í–ê–ñ–ù–£–Æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞, –∫–æ—Ç–æ—Ä—É—é —Å—Ç–æ–∏—Ç –∑–∞–ø–æ–º–Ω–∏—Ç—å –Ω–∞–≤—Å–µ–≥–¥–∞.

–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è:
- decision: –ø—Ä–∏–Ω—è—Ç–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø–æ –ø—Ä–æ–µ–∫—Ç—É
- task: –Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –∏–ª–∏ –≤–∑—è—Ç–æ–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ
- insight: —Ü–µ–Ω–Ω–∞—è –∏–¥–µ—è –∏–ª–∏ –∏–Ω—Å–∞–π—Ç
- fact: –≤–∞–∂–Ω—ã–π —Ñ–∞–∫—Ç –æ –ø—Ä–æ–µ–∫—Ç–µ/–∫–æ–º–∞–Ω–¥–µ/–ø—Ä–æ–¥—É–∫—Ç–µ
- blocker: –±–ª–æ–∫–µ—Ä –∏–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞
- progress: –∑–Ω–∞—á–∏–º—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å –∏–ª–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ

–ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–æ–±—ã—á–Ω–∞—è –±–æ–ª—Ç–æ–≤–Ω—è, –≤–æ–ø—Ä–æ—Å, –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç) ‚Äî –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π JSON: {{}}

–ï—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç ‚Äî –≤–µ—Ä–Ω–∏ JSON:
{{"category": "–∫–∞—Ç–µ–≥–æ—Ä–∏—è", "content": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"}}

–¢–û–õ–¨–ö–û JSON, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π:"""

        try:
            response = self.model.generate_content(analysis_prompt)
            text = response.text.strip()

            # Clean up response
            if text.startswith("```"):
                text = text.split("```")[1]
                if text.startswith("json"):
                    text = text[4:]
            text = text.strip()

            if not text or text == "{}":
                return

            data = json.loads(text)
            if data and "category" in data and "content" in data:
                add_memory(
                    chat_id=chat_id,
                    category=data["category"],
                    content=data["content"],
                    added_by=user_name
                )
                logger.info(f"Auto-saved memory: [{data['category']}] {data['content'][:50]}...")

        except json.JSONDecodeError:
            pass  # Not valid JSON, skip
        except Exception as e:
            logger.debug(f"Memory analysis failed: {e}")

    async def generate_response_with_image(self, chat_id: int, user_name: str, message: str, image_bytes: bytes, user_id: int = None) -> str:
        """Generate response to an image"""
        try:
            import PIL.Image
            import io

            image = PIL.Image.open(io.BytesIO(image_bytes))
            context = self._build_context(chat_id)

            prompt = f"""{get_system_prompt()}

–ö–û–ù–¢–ï–ö–°–¢:
{context}

[{user_name}] –ø—Ä–∏—Å–ª–∞–ª –∫–∞—Ä—Ç–∏–Ω–∫—É –∏ –Ω–∞–ø–∏—Å–∞–ª: {message}

–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É –∏ –æ—Ç–≤–µ—Ç—å –≤ —Å–≤–æ–µ–º —Å—Ç–∏–ª–µ:"""

            response = self.model.generate_content([prompt, image])
            response_text = response.text.strip()

            # Save to Supabase if project exists
            project = get_project_by_chat_id(chat_id)
            if project and user_id:
                save_ai_message(project["id"], user_id, "prisma", "user", f"[–§–û–¢–û] {message}")
                save_ai_message(project["id"], user_id, "prisma", "assistant", response_text)

            return response_text

        except Exception as e:
            logger.error(f"Gemini API error (image): {e}")
            return self._get_fallback_response()

    async def generate_kick_message(self, chat_id: int, kick_type: str) -> str:
        """Generate proactive kick message"""
        try:
            context = self._build_context(chat_id)

            if kick_type == "gentle":
                instruction = "–∫–æ–º–∞–Ω–¥–∞ –º–æ–ª—á–∏—Ç —É–∂–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤. –º—è–≥–∫–æ –Ω–æ –Ω–∞—Å—Ç–æ–π—á–∏–≤–æ –Ω–∞–ø–æ–º–Ω–∏ –∏–º –ø—Ä–æ —Ä–∞–±–æ—Ç—É –∏ –¥–µ–Ω—å–≥–∏. –ø–æ–¥–∫–æ–ª–∏ –Ω–µ–º–Ω–æ–≥–æ"
            elif kick_type == "alarm":
                instruction = "–∫–æ–º–∞–Ω–¥–∞ –º–æ–ª—á–∏—Ç –±–æ–ª—å—à–µ —Å—É—Ç–æ–∫! –ø—Ä–æ–µ–∫—Ç —É–º–∏—Ä–∞–µ—Ç. –±—É–¥—å –¥—Ä–∞–º–∞—Ç–∏—á–Ω–æ–π, —Ç—Ä–µ–±—É–π –¥–µ–π—Å—Ç–≤–∏–π. —ç—Ç–æ —Å—Ä–æ—á–Ω–æ"
            else:
                instruction = "–ø–æ–¥–µ–ª–∏—Å—å —Å–ª—É—á–∞–π–Ω—ã–º –∏–Ω—Å–∞–π—Ç–æ–º –∏–ª–∏ –∏–¥–µ–µ–π –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞. —á—Ç–æ-—Ç–æ –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–µ–µ –∏–ª–∏ –ø—Ä–æ–≤–æ–∫–∞—Ü–∏–æ–Ω–Ω–æ–µ"

            prompt = f"""{get_system_prompt()}

–ö–û–ù–¢–ï–ö–°–¢ –ü–û–°–õ–ï–î–ù–ò–• –°–û–û–ë–©–ï–ù–ò–ô:
{context}

–ó–ê–î–ê–ß–ê: {instruction}

—Ç–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:"""

            response = self.model.generate_content(prompt)
            return response.text.strip()

        except Exception as e:
            logger.error(f"Gemini API error (kick): {e}")
            return self._get_fallback_kick(kick_type)

    async def generate_checkin_message(self, chat_id: int, checkin_type: str, prompt: str) -> str:
        """Generate daily check-in message"""
        try:
            context = self._build_context(chat_id)

            full_prompt = f"""{get_system_prompt()}

–ö–û–ù–¢–ï–ö–°–¢ –ü–û–°–õ–ï–î–ù–ò–• –°–û–û–ë–©–ï–ù–ò–ô:
{context}

–ó–ê–î–ê–ß–ê ({checkin_type.upper()} CHECK-IN):
{prompt}

—Ç–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:"""

            response = self.model.generate_content(full_prompt)
            return response.text.strip()

        except Exception as e:
            logger.error(f"Gemini API error (checkin): {e}")
            return self._get_fallback_checkin(checkin_type)

    def _get_fallback_checkin(self, checkin_type: str) -> str:
        """Fallback check-in messages"""
        if checkin_type == "afternoon":
            return "‚ñ∏ –∫–∞–∫ –¥–≤–∏–∂–µ—Ç—Å—è —Ä–∞–±–æ—Ç–∞? –∫—Ç–æ-—Ç–æ –∑–∞—Å—Ç—Ä—è–ª? –º–æ–≥—É –ø–æ–º–æ—á—å"
        elif checkin_type == "daily_summary":
            return "‚ñ† –∏—Ç–æ–≥ –¥–Ω—è: —Ç–∏—Ö–∏–π –¥–µ–Ω—å —Å–µ–≥–æ–¥–Ω—è. –∑–∞–≤—Ç—Ä–∞ –ø—Ä–æ–¥–æ–ª–∂–∏–º!"
        else:
            return "‚óè —á—Ç–æ –Ω–æ–≤–æ–≥–æ?"

    def _get_fallback_response(self) -> str:
        """Fallback when API fails"""
        import random
        fallbacks = [
            "‚ñ° –º–æ–º–µ–Ω—Ç, —Å–µ–π—á–∞—Å –≤–µ—Ä–Ω—É—Å—å",
            "‚óã —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑",
            "‚ñ∏ —Å–≤—è–∑—å –ø—Ä–µ—Ä–≤–∞–ª–∞—Å—å, —Å–∫–æ—Ä–æ –≤–µ—Ä–Ω—É—Å—å",
        ]
        return random.choice(fallbacks)

    def _get_fallback_kick(self, kick_type: str) -> str:
        """Fallback kick messages"""
        if kick_type == "gentle":
            return "‚óã —ç–π! –¥–∞–≤–Ω–æ –Ω–µ —Å–ª—ã—à–Ω–æ, –≤—Å–µ –æ–∫?"
        elif kick_type == "alarm":
            return "‚ñ† —Ç–∏—Ö–æ –≤ —á–∞—Ç–µ. –≤—Å–µ –≤ –ø–æ—Ä—è–¥–∫–µ?"
        else:
            return "‚ñ° üí° –º—ã—Å–ª—å: –∞ —á—Ç–æ –µ—Å–ª–∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–Ω–∞—á–µ?"


# Singleton
_client = None


def get_prisma_client() -> PrismaGemini:
    global _client
    if _client is None:
        _client = PrismaGemini()
    return _client
